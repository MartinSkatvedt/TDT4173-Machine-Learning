{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87679f48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 9.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh import extract_features, select_features, extract_relevant_features\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore, boxcox\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b0b2b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Window:\n",
    "    def __init__(self, targets, window_size=100):\n",
    "        self.targets = targets\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.start = 0\n",
    "        self.end = self.window_size\n",
    "\n",
    "\n",
    "    def get(self):\n",
    "        return self.targets[self.start: self.end]\n",
    "\n",
    "    def next(self):\n",
    "        self.start += 1\n",
    "        self.end += 1\n",
    "\n",
    "    def hasNext(self):\n",
    "        if self.end < len(self.targets):\n",
    "            return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ff3383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Building:\n",
    "    def __init__(self, train_x, train_y, val_x, val_y, test_x):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        \n",
    "        self.val_x = val_x\n",
    "        self.val_y = val_y\n",
    "        \n",
    "        self.test_x = test_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26ca2bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    def __init__(self, train_a, train_b, train_c, observed_a, \n",
    "                 observed_b, observed_c, estimated_a, estimated_b, estimated_c, test_a, test_b, test_c):\n",
    "        \n",
    "        self.observed_a = self.quartersToHours(observed_a)\n",
    "        self.observed_b = self.quartersToHours(observed_b)\n",
    "        self.observed_c = self.quartersToHours(observed_c)\n",
    "        \n",
    "        self.estimated_a = self.quartersToHours(estimated_a)\n",
    "        self.estimated_a = self.estimated_a.drop([\"date_calc\"], axis=1)\n",
    "        \n",
    "        self.estimated_b = self.quartersToHours(estimated_b)\n",
    "        self.estimated_b = self.estimated_b.drop([\"date_calc\"], axis=1)\n",
    "        \n",
    "        self.estimated_c = self.quartersToHours(estimated_c)\n",
    "        self.estimated_c = self.estimated_c.drop([\"date_calc\"], axis=1)\n",
    "\n",
    "        self.test_a = self.quartersToHours(test_a)\n",
    "        self.test_a = self.test_a.drop([\"date_calc\"], axis=1)\n",
    "        self.test_a = self.test_a.rename(columns={'date_forecast': 'date'})\n",
    "        \n",
    "        self.test_b = self.quartersToHours(test_b)\n",
    "        self.test_b = self.test_b.drop([\"date_calc\"], axis=1)\n",
    "        self.test_b = self.test_b.rename(columns={'date_forecast': 'date'})\n",
    "\n",
    "        self.test_c = self.quartersToHours(test_c)\n",
    "        self.test_c = self.test_c.drop([\"date_calc\"], axis=1)\n",
    "        self.test_c = self.test_c.rename(columns={'date_forecast': 'date'})\n",
    "        \n",
    "        \n",
    "        self.train_a = train_a\n",
    "        self.train_b = train_b\n",
    "        self.train_c = train_c\n",
    "        \n",
    "        self.data_a = self.join_data(self.observed_a, self.estimated_a, self.train_a)\n",
    "        self.data_b = self.join_data(self.observed_b, self.estimated_b, self.train_b)\n",
    "        self.data_c = self.join_data(self.observed_c, self.estimated_c, self.train_c)\n",
    "        \n",
    "                \n",
    "        self.data_a = self.data_a.fillna(0)\n",
    "        self.test_a = self.test_a.fillna(0)\n",
    "\n",
    "        self.data_b = self.data_b.fillna(0)\n",
    "        self.test_b = self.test_b.fillna(0)\n",
    "\n",
    "        self.data_c = self.data_c.fillna(0)\n",
    "        self.test_c = self.test_c.fillna(0)\n",
    "        \n",
    "        \n",
    "        self.training_data = [self.data_a, self.data_b, self.data_c]\n",
    "        self.test_data = [self.test_a, self.test_b, self.test_c]\n",
    "        \n",
    "        \n",
    "        self.process()\n",
    "\n",
    "    \n",
    "    \n",
    "    def join_data(self, observed, estimated, labels):\n",
    "        #Remove hour and minute values\n",
    "        observed = observed.assign(date_forecast=observed.date_forecast.dt.round('H'))\n",
    "        estimated = estimated.assign(date_forecast=estimated.date_forecast.dt.round('H'))\n",
    "\n",
    "        #rename columns names to match\n",
    "        observed = observed.rename(columns={'date_forecast': 'date'})\n",
    "        estimated = estimated.rename(columns={'date_forecast': 'date'})\n",
    "        labels = labels.rename(columns={'time': 'date'})\n",
    "\n",
    "        data = pd.concat([observed, estimated])\n",
    "        joined_data = pd.merge(data, labels, how=\"inner\", on=\"date\")\n",
    "\n",
    "        return joined_data\n",
    "\n",
    "\n",
    "    def quartersToHours(self, df):\n",
    "        df['date_forecast'] = pd.to_datetime(df['date_forecast'], format='%Y-%m.%d %H:%M:%S')\n",
    "        df[\"year\"] = df['date_forecast'].dt.year\n",
    "        df[\"month\"] = df['date_forecast'].dt.month\n",
    "        df[\"day\"] = df['date_forecast'].dt.day\n",
    "        df[\"hour\"] = df['date_forecast'].dt.hour\n",
    "\n",
    "\n",
    "        group = df.groupby([df[\"year\"], df[\"month\"], df[\"day\"], df[\"hour\"]])  \n",
    "        result = group.mean()\n",
    "        result = result.reset_index()\n",
    "\n",
    "        return_df = result.drop(['year','month', 'day', 'hour'], axis=1)\n",
    "\n",
    "        return return_df\n",
    "    \n",
    "    def find_and_delete_constants(self, df):\n",
    "        WINDOW_SIZE = 24\n",
    "\n",
    "        window = Window(df[\"pv_measurement\"], WINDOW_SIZE)\n",
    "\n",
    "        constants = []\n",
    "\n",
    "        while window.hasNext():\n",
    "            if window.get().std() <= 0.1:\n",
    "                constants.append((window.start, window.end))\n",
    "            window.next()\n",
    "\n",
    "        def extract_indices(ranges):\n",
    "            return [start for start, _ in ranges]\n",
    "\n",
    "\n",
    "        indices = extract_indices(constants)\n",
    "\n",
    "\n",
    "        df = df.drop(indices)\n",
    "        df = df.reset_index()\n",
    "        df = df.drop(['index'], axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def convert_date_to_sin_and_cos(self, df):\n",
    "        day = 24*60*60 #seconds in a day\n",
    "        year = (365.2425)*day #seconds in a year\n",
    "        month = year / 12.0\n",
    "\n",
    "        date_time = pd.to_datetime(df['date'], format='%Y-%m.%d %H:%M:%S')\n",
    "\n",
    "        timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "        #df['Month sin'] = np.sin(timestamp_s * (2 * np.pi / month))\n",
    "        #df['Month cos'] = np.cos(timestamp_s * (2 * np.pi / month))\n",
    "\n",
    "        df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "        df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "\n",
    "        df['Hour sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "        df['Hour cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def round_is_day(self, df):\n",
    "        df[\"is_day:idx\"] = [int(round(df[\"is_day:idx\"][i])) for i in range(len(df))]\n",
    "        df[\"is_in_shadow:idx\"] = [int(round(df[\"is_in_shadow:idx\"][i])) for i in range(len(df))]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def combine_features(self, df):\n",
    "        \n",
    "        new_features = [\n",
    "            [['direct_rad:W', 'diffuse_rad:W'], 'global_rad:W'],\n",
    "            [['direct_rad_1h:J', 'diffuse_rad_1h:J'], 'global_rad_1h:J']]\n",
    "        \n",
    "        for features, new_name in new_features:\n",
    "    \n",
    "            totals = []\n",
    "\n",
    "            for i in range(len(df)):\n",
    "                total = 0\n",
    "                for feature in features:\n",
    "                    total += df[feature][i]\n",
    "\n",
    "                totals.append(total)\n",
    "            df[new_name] = totals\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def remove_unused_columns(self, df):\n",
    "        df = df.drop(['snow_drift:idx', 'elevation:m', \"rain_water:kgm2\", \"rain_water:kgm2\",\n",
    "                      \"wind_speed_w_1000hPa:ms\"], axis=1)\n",
    "        return df\n",
    "    \n",
    "    def split_data(self, df):\n",
    "        val_split = 0.2\n",
    "\n",
    "        len_df = len(df)\n",
    "        train_len = int(len_df * (1.0 - val_split))\n",
    "\n",
    "        train = df.iloc[:train_len,:]\n",
    "        val = df.iloc[train_len:,:]\n",
    "\n",
    "\n",
    "        train = train.reset_index()\n",
    "        train = train.drop(['index'], axis=1)\n",
    "\n",
    "        val = val.reset_index()\n",
    "        val = val.drop(['index'], axis=1)\n",
    "\n",
    "        return train, val\n",
    "    \n",
    "    def createFeatures(self, df): \n",
    "        top5 = ['absolute_humidity_2m:gm3', 'ceiling_height_agl:m', 'air_density_2m:kgm3', 'cloud_base_agl:m', 'sun_azimuth:d'] \n",
    "        seenKombos = []\n",
    "        toCombine = [('effective_cloud_cover:p', 'clear_sky_energy_1h:J')]\n",
    "        for elem in top5:\n",
    "            for elem_2 in top5:\n",
    "                if (elem, elem_2) not in seenKombos:\n",
    "                    seenKombos.append((elem, elem_2))\n",
    "                    if elem != elem_2:\n",
    "                        toCombine.append((elem, elem_2))\n",
    "\n",
    "        for col in df:\n",
    "            if col == \"date\":\n",
    "                continue\n",
    "            for col_2 in df:\n",
    "                if col_2 == \"date\":\n",
    "                    continue\n",
    "                if (col, col_2) not in seenKombos:\n",
    "                    seenKombos.append((col, col_2))\n",
    "                    if col != col_2 and (col in top5 or col_2 in top5):\n",
    "                        if abs(df[col].corr(df[col_2])) >= 0.8:\n",
    "                            toCombine.append((col, col_2))\n",
    "\n",
    "        #print(\"toComb: \", toCombine)\n",
    "        #print(\"------------------------\")\n",
    "        created = []\n",
    "        for i in range(len(toCombine)):\n",
    "            df[toCombine[i][0] + '_' + toCombine[i][1]] = df[toCombine[i][0]] * df[toCombine[i][1]]\n",
    "        return df\n",
    "    \n",
    "    def apply(self, data, function):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = function(data[i])\n",
    "            \n",
    "    def process(self):\n",
    "        #PV constants\n",
    "        self.apply(self.training_data, self.find_and_delete_constants)\n",
    "  \n",
    "        \n",
    "        #Time sin and cos\n",
    "        self.apply(self.training_data, self.convert_date_to_sin_and_cos)\n",
    "        self.apply(self.test_data, self.convert_date_to_sin_and_cos)\n",
    "        \n",
    "        #Round isday and isshadow\n",
    "        self.apply(self.training_data, self.round_is_day)\n",
    "        self.apply(self.test_data, self.round_is_day)\n",
    "        \n",
    "        #combine\n",
    "        self.apply(self.training_data, self.combine_features)\n",
    "        self.apply(self.test_data, self.combine_features)\n",
    "        \n",
    "        #fill Nan\n",
    "        for i in range(len(self.training_data)):\n",
    "            self.training_data[i] = self.training_data[i].fillna(0)\n",
    "            \n",
    "        for i in range(len(self.test_data)):\n",
    "            self.test_data[i] = self.test_data[i].fillna(0)\n",
    "        \n",
    "        #remove unsused\n",
    "        self.apply(self.training_data, self.remove_unused_columns)\n",
    "        self.apply(self.test_data, self.remove_unused_columns)\n",
    "    \n",
    "        \n",
    "        for i in range(len(self.training_data)):\n",
    "            z = self.training_data[i].drop(\"date\", axis=1).apply(zscore)\n",
    "            \n",
    "            hasBigOutliers = []\n",
    "            for col in z:\n",
    "                if col == \"date\" or col == \"pv_measurement\":\n",
    "                    continue\n",
    "                for val in z[col]:\n",
    "                    if val >= 10:\n",
    "                        hasBigOutliers.append(col)\n",
    "                        break\n",
    "                    \n",
    "            for col in hasBigOutliers:\n",
    "                self.training_data[i][col] = boxcox(self.training_data[i][col] + 1)[0]\n",
    "                if self.test_data[i][col].std() != 0.0:\n",
    "                    self.test_data[i][col] = boxcox(self.test_data[i][col] + 1)[0]  \n",
    "  \n",
    "        for i in range(len(self.training_data)):\n",
    "            temp = self.training_data[i].pop(\"pv_measurement\")\n",
    "            temp_data = pd.concat([self.training_data[i], self.test_data[i]])\n",
    "            res = self.createFeatures(temp_data)\n",
    "            \n",
    "            train = res[:len(temp)]\n",
    "            train[\"pv_measurement\"] = temp\n",
    "            test = res[len(temp):]\n",
    "            \n",
    "            self.training_data[i] = train\n",
    "            self.test_data[i] = test\n",
    "            \n",
    "            \n",
    "        new_train = []\n",
    "        new_test = []\n",
    "        for i in range(len(self.training_data)):\n",
    "            print(f'tsfresh feature extraction on building {[\"A\", \"B\", \"C\"][i]}')\n",
    "            train_with_index = self.training_data[i].reset_index()\n",
    "            test_with_index = self.test_data[i].reset_index()\n",
    "\n",
    "            extracted_train_features = extract_features(train_with_index[[\"date\", \"index\", \"global_rad:W\"]], \n",
    "                                                        column_id=\"index\", \n",
    "                                                        column_sort=\"date\", \n",
    "                                                        default_fc_parameters=EfficientFCParameters())\n",
    "            \n",
    "            extracted_test_features = extract_features(test_with_index[[\"date\", \"index\", \"global_rad:W\"]], \n",
    "                                                        column_id=\"index\", \n",
    "                                                        column_sort=\"date\", \n",
    "                                                        default_fc_parameters=EfficientFCParameters())\n",
    "\n",
    "            \n",
    "            \n",
    "            impute(extracted_train_features)\n",
    "            features_filtered = select_features(extracted_train_features, train_with_index[\"pv_measurement\"], ml_task=\"regression\")\n",
    "            valid_test_cols = pd.DataFrame()\n",
    "            for col in features_filtered:\n",
    "                valid_test_cols[col] = extracted_test_features[col]\n",
    "                \n",
    "            final_train = pd.merge(train_with_index, features_filtered.reset_index(), on=\"index\")\n",
    "            final_train.drop(\"index\", axis=1, inplace=True)\n",
    "            \n",
    "            final_test = pd.merge(test_with_index, valid_test_cols.reset_index(), on=\"index\")\n",
    "            final_test.drop(\"index\", axis=1, inplace=True)\n",
    "            \n",
    "            new_train.append(final_train)\n",
    "            new_test.append(final_test)\n",
    "            \n",
    "        self.training_data = new_train\n",
    "        self.test_data = new_test\n",
    "\n",
    "\n",
    "        train_data_a, val_data_a = self.split_data(self.training_data[0])\n",
    "        train_data_b, val_data_b = self.split_data(self.training_data[1])\n",
    "        train_data_c, val_data_c = self.split_data(self.training_data[2])\n",
    "        \n",
    "        train_data_a.drop([\"date\"], axis=1, inplace=True)\n",
    "        val_data_a.drop([\"date\"], axis=1, inplace=True)\n",
    "        self.test_data[0].drop([\"date\"], axis=1, inplace=True)\n",
    "\n",
    "        train_data_b.drop([\"date\"], axis=1, inplace=True)\n",
    "        val_data_b.drop([\"date\"], axis=1, inplace=True)\n",
    "        self.test_data[1].drop([\"date\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        train_data_c.drop([\"date\"], axis=1, inplace=True)\n",
    "        val_data_c.drop([\"date\"], axis=1, inplace=True)\n",
    "        self.test_data[2].drop([\"date\"], axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        train_a_y = train_data_a.pop(\"pv_measurement\")\n",
    "        val_a_y = val_data_a.pop(\"pv_measurement\")\n",
    "\n",
    "        train_b_y = train_data_b.pop(\"pv_measurement\")\n",
    "        val_b_y = val_data_b.pop(\"pv_measurement\")\n",
    "\n",
    "        train_c_y = train_data_c.pop(\"pv_measurement\")\n",
    "        val_c_y = val_data_c.pop(\"pv_measurement\")\n",
    "        \n",
    "\n",
    "        \n",
    "        self.A = Building(train_data_a, train_a_y, val_data_a, val_a_y, self.test_data[0])\n",
    "        self.B = Building(train_data_b, train_b_y, val_data_b, val_b_y, self.test_data[1])\n",
    "        self.C = Building(train_data_c, train_c_y, val_data_c, val_c_y, self.test_data[2])\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
